1. Natural Language Toolkit - NLTK is a leading platform for building
Python programs to work with human language data. It provides easy-to-use
interfaces to over 50 corpora and lexical resources such as WordNet, along
with a suite of text processing libraries for classification, tokenization,
stemming, tagging, parsing, and semantic reasoning, wrappers for industrialstrength
NLP libraries, and an active discussion forum.
Used for text preprocessing tasks such as -
1.1 Text Cleaning- Removal of unnecessary symbols such as @, #, $, %.
1.2 Stopwords- Stopwords is a list containing words which are not relevant
or which do not give the insight for example - words such as this, for, very,
much, many.
1.3 Tokenizer - Tokenization is the process by which big quantity of text is
divided into smaller parts called tokens.
1.4 Stemming- To convert similar words into a single word as to reduce the
size of Sparse matrix.
1.5 Bag Of Words- To create a sparse matrix of all words with their
frequency of occurrence.

2. Pandas- Pandas is an open source, Berkeley Source Distribution (BSD)-
licensed library providing high-performance, easy-to-use data structures and
data analysis tools for the Python programming language. Pandas is a
NumFOCUS sponsored project. This will help ensure the success of
development of pandas as a world-class open-source project, and makes it
possible to donate to the project.
Used for Importing the dataset and plotting a box-plot of the dataset.
3. Scikit-learn- Scikit-learn (formerly scikits.learn and also known as
sklearn) is a free software machine learning library for the Python
programming language. It features various classification, regression and
clustering algorithms including support vector machines, random forests,
gradient boosting, k-means etc, and is designed to interoperate with the
Python numerical and scientific libraries NumPy and SciPy.
All the work of training and testing on various models is done by this library
such as:
3.1 Train test and split-To split the dataset into training and test set.
3.2 Feature Extraction and cleaning the text ( stemming, tokenising etc.)
while creating the bag of words models.
3.3 Statistical analysis such as the mean squared error, the variance and the
cohen’s kappa score .
3.4 Implementation of all the regression models .
3.5 Cross-validation and Grid Search CV for K- fold cross validation

4. Matplotlib - Matplotlib is a Python 2D plotting library which produces
publication quality figures in a variety of hardcopy formats and interactive
environments across platforms. Matplotlib can be used in Python scripts, the
Python and IPython shells, the Jupyter notebook, web application servers,
and four graphical user interface toolkits.
Used for plotting various graphs at various stages of the project
5. Numpy - NumPy is the fundamental package for scientific computing with
Python. It contains among other things:
● a powerful N-dimensional array object
● sophisticated (broadcasting) functions
● tools for integrating C/C++ and Fortran code
● useful linear algebra, Fourier transform, and random number capabilities
Besides its obvious scientific uses, NumPy can also be used as an efficient
multi-dimensional container of generic data. Arbitrary data-types can be
defined. This allows NumPy to seamlessly and speedily integrate with a
wide variety of databases.
NumPy is licensed under the BSD license, enabling reuse with few
restrictions.
Used for creating arrays and performing various operations on arrays as
arrays are faster than lists .
